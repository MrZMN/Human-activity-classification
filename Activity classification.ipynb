{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "896d8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a1c85",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "937cdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_signal(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        data = fp.read().splitlines()\n",
    "        data = map(lambda x: x.rstrip().lstrip().split(), data)\n",
    "        data = [list(map(float, line)) for line in data]\n",
    "    return data\n",
    "\n",
    "def read_label(filename):        \n",
    "    with open(filename, 'r') as fp:\n",
    "        labels = fp.read().splitlines()\n",
    "        labels = list(map(int, labels))\n",
    "    return labels\n",
    "\n",
    "def read_data():\n",
    "    train_folder = 'train_data/'\n",
    "    test_folder = 'test_data/'\n",
    "    train_signals, test_signals = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    \n",
    "    for input_file in sorted(os.listdir(train_folder)):\n",
    "        if not input_file.startswith('.'):\n",
    "            signal = read_signal(train_folder + input_file)\n",
    "            train_signals.append(signal)\n",
    "    train_signals = np.transpose(np.array(train_signals), (1, 2, 0))\n",
    "    for input_file in sorted(os.listdir(test_folder)):\n",
    "        if not input_file.startswith('.'):\n",
    "            signal = read_signal(test_folder + input_file)\n",
    "            test_signals.append(signal)\n",
    "    test_signals = np.transpose(np.array(test_signals), (1, 2, 0))\n",
    "    \n",
    "    train_labels = read_label('y_train.txt')\n",
    "    test_labels = read_label('y_test.txt')\n",
    "    \n",
    "    return train_signals, train_labels, test_signals, test_labels\n",
    "    # (7352*128*n), (7352*1); (2947*128*n), (2947*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31bb04",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ec2d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(signal):\n",
    "    mean = np.nanmean(signal)\n",
    "    std = np.nanstd(signal)\n",
    "    maxval = np.nanmax(signal)\n",
    "    minval = np.nanmin(signal)\n",
    "    maxidx = np.nanargmax(signal)\n",
    "    minidx = np.nanargmin(signal)\n",
    "    m_deri = np.mean(np.gradient(signal)) \n",
    "    no_zero_crossings = len(np.nonzero(np.diff(np.array(signal) > 0))[0])\n",
    "    no_mean_crossings = len(np.nonzero(np.diff(np.array(signal) > np.nanmean(signal)))[0])  \n",
    "    return [mean, std, maxval, minval, maxidx, minidx, m_deri, no_zero_crossings, no_mean_crossings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c0111",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9e729b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(dataset, waveletname):\n",
    "    win_feature = []\n",
    "    # num of windows (2.56 s/window)\n",
    "    for win_no in range(0, len(dataset)):    \n",
    "        file_feature = []\n",
    "        # num of files\n",
    "        for file_no in range(0, dataset.shape[2]):  \n",
    "            \n",
    "            segment = dataset[win_no, :, file_no]    # raw data (128 elements/seg)\n",
    "            \n",
    "            # DWT (baseline)\n",
    "            dwt_data = pywt.wavedec(segment, waveletname)        # select all components\n",
    "            #dwt_data = pywt.wavedec(segment, waveletname)[0:2]  # select the deepest level\n",
    "            \n",
    "            # feature extraction\n",
    "            for level in dwt_data:\n",
    "                file_feature += features(level)\n",
    "                \n",
    "        win_feature.append(file_feature)\n",
    "    \n",
    "    feature = np.array(win_feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dd5a49b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352 128 9\n",
      "2947 128 9\n",
      "7352 1\n",
      "7352 162\n",
      "2947 162\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_label = read_data()\n",
    "train_label = np.reshape(np.array(train_label).T, (-1, 1))\n",
    "print(train_data.shape[0], train_data.shape[1], train_data.shape[2])\n",
    "print(test_data.shape[0], test_data.shape[1], test_data.shape[2])\n",
    "\n",
    "train_data = extract_feature(train_data, 'db4')\n",
    "test_data  = extract_feature(test_data, 'db4')\n",
    "#train_data = extract_feature(train_data, 'coif5')\n",
    "#test_data  = extract_feature(test_data, 'coif5')\n",
    "print(train_data.shape[0], train_data.shape[1])\n",
    "print(test_data.shape[0], test_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07653766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test on Weka\n",
    "np.savetxt('data.txt', np.concatenate((train_data, train_label), axis=1), delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce45d5c",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4f264",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756c5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.8665669205658324\n",
      "Accuracy on test set: 0.7838479809976246\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024cd67",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531eeadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.832371903630811\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=1000)\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b03d7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a42f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.8215134034611469\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31783bf",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873aefd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.8071273122959739\n",
      "Accuracy on test set: 0.7387173396674585\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5522e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f739afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.8803046789989118\n",
      "Accuracy on test set: 0.8137088564642009\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 10000)\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b125c0",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e671ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 0.7522904648795385\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140b075",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74be5621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.7969260065288357\n",
      "Accuracy on test set: 0.6359009161859518\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(train_data, train_label)\n",
    "train_score = model.score(train_data, train_label)\n",
    "test_score = model.score(test_data, test_label)\n",
    "print(\"Accuracy on training set: {}\".format(train_score))\n",
    "print(\"Accuracy on test set: {}\".format(test_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
